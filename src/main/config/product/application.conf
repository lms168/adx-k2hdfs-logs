akka{
  # 日志级别， DEBUG, INFO
  loglevel = "DEBUG"
  # do not edit this
  loggers = ["akka.event.slf4j.Slf4jLogger"]
}


main {
  name = "hello"
  http {
    host = "0.0.0.0"
    port = 7777
  }
}

akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 10000
  kafka-clients {
    bootstrap.servers = "adx01:9092"
    #  bootstrap.servers = "127.0.0.1:9092"
    acks = "all"
    retries = 5
    batch.size = 16384
    linger.ms = 1
    buffer.memory = 33554432
  }
}


# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that blocking of the thread that
  # is executing the stage will be blocked.
  poll-timeout = 50ms

  # The stage will be await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `TimeoutException`.
  commit-timeout = 15s

  # If the KafkaConsumer can't connect to the broker the poll will be
  # aborted after this timeout. The KafkaConsumerActor will throw
  # org.apache.kafka.common.errors.WakeupException which will be ignored
  # until max-wakeups limit gets exceeded.
  wakeup-timeout = 3s

  # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
  max-wakeups = 10

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    auto.offset.reset = "latest"
    bootstrap.servers = "adx01:9092"
    # Disable auto-commit by default
    enable.auto.commit = false
  }
}

kafka.topic-out = "adx-logs"

kafka.consumer {
  topics = ["adx-logs"]
  groupId = "group-adxlogs"
}



adx-logs.file {
  //已上传文件前缀
  uploadedSign = "uploaded-"
  //正点写入文件前缀
  onTimeFileSign = "0-"
  //文件5分钟没有发生变更则认为该文件可以上传了
  uploadWaitTime = 300000

  original {
    rootPath = "/home/adx-logs_localhost/original/"
    fileName = "adx-logs.txt"
  }
  formate{
    rootPath = "/home/adx-logs_localhost/formate/"
    fileName = "adx-logs.txt"
  }

}


upload {
  //用户
  user = "root"
  //hdfs地址
  defaultFS = "hdfs://adx01:9000"
  //要上传的本地文件路径
  srcPath = ${adx-logs.file.formate.rootPath}
  //要上传的hdfs路径
  destHdfsPath = "/"
}